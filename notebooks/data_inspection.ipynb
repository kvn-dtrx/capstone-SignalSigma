{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import holidays \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "data = '2012-12-30'\n",
    "\n",
    "path_stock = \"../data/stock\"\n",
    "path_fed = \"../data/fed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 Tech Companies based on Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_df = pd.read_csv(f\"{path_stock}/AAPL_stock.csv\")\n",
    "MSFT_df = pd.read_csv(f\"{path_stock}/MSFT_stock.csv\")\n",
    "GOOGL_df = pd.read_csv(f\"{path_stock}/GOOGL_stock.csv\")\n",
    "NVDA_df = pd.read_csv(f\"{path_stock}/NVDA_stock.csv\")\n",
    "AMZN_df = pd.read_csv(f\"{path_stock}/AMZN_stock.csv\")\n",
    "META_df = pd.read_csv(f\"{path_stock}/META_stock.csv\")\n",
    "TSLA_df = pd.read_csv(f\"{path_stock}/TSLA_stock.csv\")\n",
    "AVGO_df = pd.read_csv(f\"{path_stock}/AVGO_stock.csv\")\n",
    "AMD_df = pd.read_csv(f\"{path_stock}/AMD_stock.csv\")\n",
    "CRM_df = pd.read_csv(f\"{path_stock}/CRM_stock.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['date', 'close_AAPL', 'high_AAPL', 'low_AAPL', 'open_AAPL',\n",
    "       'volume_AAPL', 'delta_price_AAPL', 'avg_price_AAPL', 'price_ratio_AAPL',\n",
    "       'invest_AAPL']\n",
    "['date', 'close_MSFT', 'high_MSFT', 'low_MSFT', 'open_MSFT',\n",
    "       'volume_MSFT', 'delta_price_MSFT', 'avg_price_MSFT', 'price_ratio_MSFT',\n",
    "       'invest_MSFT']\n",
    "['date', 'close_GOOGL', 'high_GOOGL', 'low_GOOGL', 'open_GOOGL',\n",
    "       'volume_GOOGL', 'delta_price_GOOGL', 'avg_price_GOOGL',\n",
    "       'price_ratio_GOOGL', 'invest_GOOGL']\n",
    "['date', 'close_NVDA', 'high_NVDA', 'low_NVDA', 'open_NVDA',\n",
    "       'volume_NVDA', 'delta_price_NVDA', 'avg_price_NVDA', 'price_ratio_NVDA',\n",
    "       'invest_NVDA']\n",
    "['date', 'close_AMZN', 'high_AMZN', 'low_AMZN', 'open_AMZN',\n",
    "       'volume_AMZN', 'delta_price_AMZN', 'avg_price_AMZN', 'price_ratio_AMZN',\n",
    "       'invest_AMZN']\n",
    "['date', 'close_META', 'high_META', 'low_META', 'open_META',\n",
    "       'volume_META', 'delta_price_META', 'avg_price_META', 'price_ratio_META',\n",
    "       'invest_META']\n",
    "['date', 'close_TSLA', 'high_TSLA', 'low_TSLA', 'open_TSLA',\n",
    "       'volume_TSLA', 'delta_price_TSLA', 'avg_price_TSLA', 'price_ratio_TSLA',\n",
    "       'invest_TSLA']\n",
    "['date', 'close_AVGO', 'high_AVGO', 'low_AVGO', 'open_AVGO',\n",
    "       'volume_AVGO', 'delta_price_AVGO', 'avg_price_AVGO', 'price_ratio_AVGO',\n",
    "       'invest_AVGO']\n",
    "['date', 'close_AMD', 'high_AMD', 'low_AMD', 'open_AMD', 'volume_AMD',\n",
    "       'delta_price_AMD', 'avg_price_AMD', 'price_ratio_AMD', 'invest_AMD']\n",
    "\n",
    "['date', 'close_CRM', 'high_CRM', 'low_CRM', 'open_CRM', 'volume_CRM',\n",
    "       'delta_price_CRM', 'avg_price_CRM', 'price_ratio_CRM', 'invest_CRM']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tach companies stock Data Frame processing\n",
    "- Remove the null / header\n",
    "- Make some features Engineering\n",
    "- Change the column name\n",
    "- Change the time type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_stock_data(df, ticker_symbol):\n",
    "    \"\"\"\n",
    "    Processes a stock data DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with stock data (Price, Close, High, Low, Open, Volume, Ticker).\n",
    "        ticker_symbol (str): Stock ticker symbol (e.g., 'AAPL').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame with calculated features and renamed columns.\n",
    "    \"\"\"\n",
    "    df.dropna(inplace=True)  # Remove rows containing any missing values.\n",
    "\n",
    "    columns_to_convert = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    df[columns_to_convert] = df[columns_to_convert].astype(float)  # Convert specified price/volume columns to floating-point numbers.\n",
    "\n",
    "    # Calculate new features based on price data:\n",
    "    df[\"delta_price\"] = df[\"High\"] - df[\"Low\"]  # Calculate the difference between the high and low price for each day.\n",
    "    df[\"avg_price\"] = (df[\"Close\"] + df[\"High\"] + df[\"Low\"] + df[\"Open\"]) / 4  # Calculate the average of the close, high, low, and open prices.\n",
    "    df[\"price_ratio\"] = df[\"delta_price\"] / df[\"avg_price\"]  # Calculate the ratio of the delta price to the average price.\n",
    "    df[\"invest\"] = df[\"Volume\"] * df[\"avg_price\"]  # Calculate the difference between the trading volume and the average price (note: this might not be a standard financial metric and could be re-evaluated).\n",
    "\n",
    "    # Rename the columns for clarity and to include the ticker symbol:\n",
    "    df.rename(columns={\"Price\": \"date\",  # Rename the 'Price' column to 'date'.\n",
    "                        \"Close\": f\"close_{ticker_symbol}\",  # Rename 'Close' to 'cl_ticker'.\n",
    "                        \"High\": f\"high_{ticker_symbol}\",  # Rename 'High' to 'hi_ticker'.\n",
    "                        \"Low\": f\"low_{ticker_symbol}\",  # Rename 'Low' to 'lo_ticker'.\n",
    "                        \"Open\": f\"open_{ticker_symbol}\",  # Rename 'Open' to 'op_ticker'.\n",
    "                        \"delta_price\": f\"delta_price_{ticker_symbol}\",  # Rename 'delta_price' to 'de_ticker'.\n",
    "                        \"avg_price\": f\"avg_price_{ticker_symbol}\",  # Rename 'avg_price' to 'av_ticker'.\n",
    "                        \"invest\": f\"invest_{ticker_symbol}\",  # Rename 'invest' to 'va_ticker'.\n",
    "                        \"price_ratio\": f\"price_ratio_{ticker_symbol}\",  # Rename 'ratio' to 'ra_ticker'.\n",
    "                        'Volume': f'volume_{ticker_symbol}'}, inplace=True)  # Rename 'Volume' to 'Vo_ticker'.\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])  # Convert the 'date' column to datetime objects for proper time series handling.\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)  # Reset the DataFrame's index to a default integer index and drop the original index.\n",
    "\n",
    "    # Drop the 'Ticker' column as the ticker information is now embedded in the column names:\n",
    "    if 'Ticker' in df.columns:\n",
    "        df.drop('Ticker', axis=1, inplace=True)\n",
    "\n",
    "    return df  # Return the processed DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech companies stock clean Data Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_clean_df = process_stock_data(AAPL_df, 'AAPL')\n",
    "MSFT_clean_df = process_stock_data(MSFT_df, 'MSFT')\n",
    "GOOGL_clean_df = process_stock_data(GOOGL_df, 'GOOGL')\n",
    "NVDA_clean_df = process_stock_data(NVDA_df, 'NVDA')\n",
    "AMZN_clean_df = process_stock_data(AMZN_df, 'AMZN')\n",
    "META_clean_df = process_stock_data(META_df, 'META')\n",
    "TSLA_clean_df = process_stock_data(TSLA_df, 'TSLA')\n",
    "AVGO_clean_df = process_stock_data(AVGO_df, 'AVGO')\n",
    "AMD_clean_df = process_stock_data(AMD_df, 'AMD')\n",
    "CRM_clean_df = process_stock_data(CRM_df, 'CRM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Find the Max and Min od Data column in each companies stock Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data_ranges = {}\n",
    "\n",
    "dataframes = {\n",
    "    \"AAPL\": AAPL_clean_df,\n",
    "    \"MSFT\": MSFT_clean_df,\n",
    "    \"GOOGL\": GOOGL_clean_df,\n",
    "    \"NVDA\": NVDA_clean_df,\n",
    "    \"AMZN\": AMZN_clean_df,\n",
    "    \"META\": META_clean_df,\n",
    "    \"TSLA\": TSLA_clean_df,\n",
    "    \"AVGO\": AVGO_clean_df,\n",
    "    \"AMD\": AMD_clean_df,\n",
    "    \"CRM\": CRM_clean_df,\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    if 'date' in df.columns:\n",
    "        min_date = df['date'].min()\n",
    "        max_date = df['date'].max()\n",
    "        stock_data_ranges[name] = {'min_date': min_date, 'max_date': max_date}\n",
    "    else:\n",
    "        print(f\"Warning: 'date' column not found in {name}_clean_df\")\n",
    "\n",
    "# Create a Pandas DataFrame to display the results\n",
    "date_range_df = pd.DataFrame.from_dict(stock_data_ranges, orient='index')\n",
    "date_range_df.index.name = 'Stock'\n",
    "\n",
    "print(date_range_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In above result , It seems that the META is started from 2012 while almost the others started from 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro Indicators from Yahoo Finance:\n",
    "- Indices\n",
    "- Commodities\n",
    "- Sector ETFs (Proxies)\n",
    "- Other Market Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df = pd.read_csv(f\"{path_stock}/macro_indicators_full.csv\")\n",
    "# Convert the 'date' column to datetime objects\n",
    "macro_df['Date'] = pd.to_datetime(macro_df['Date'])\n",
    "macro_df.rename(columns={\"Date\": \"date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Frame : macro_df ---> Has some missing values that need to be check according to the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Filter the time after the '2012-05-31'. This is exactly after the time which we have the META stock data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_df_filter = macro_df[macro_df['date'] > data ]\n",
    "min_date_macro_df_filter = macro_df_filter['date'].min()\n",
    "max_date_macro_df_filter = macro_df_filter['date'].max()\n",
    "macro_df_filter.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#macro_df_filter = macro_df_filter.drop('Brent_Crude_Futures',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = macro_df_filter\n",
    "data_name = 'macro_df_filter'\n",
    "# 1. Matrix Plot: Visualize the pattern of missingness\n",
    "plt.figure(figsize=(10, 6))\n",
    "msno.matrix(df)\n",
    "plt.title(f'Missing Value Matrix - {data_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_clean_df = macro_df_filter.dropna()\n",
    "macro_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fed Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_df = pd.read_csv(f\"{path_fed}/combined_economic_indicators.csv\")\n",
    "\n",
    "# Rename the 'Unnamed: 0' column to 'date'\n",
    "fed_df.rename(columns={'Unnamed: 0': 'date'}, inplace=True)\n",
    "\n",
    "# Convert the 'date' column to datetime objects\n",
    "fed_df['date'] = pd.to_datetime(fed_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_df_filter = fed_df[fed_df['date'] > data]\n",
    "min_date_fed_df_filter = fed_df_filter['date'].min()\n",
    "max_date_fed_df_filter = fed_df_filter['date'].max()\n",
    "fed_df_filter.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fed_df_filter\n",
    "data_name = 'fed_df_filter'\n",
    "# 1. Matrix Plot: Visualize the pattern of missingness\n",
    "plt.figure(figsize=(10, 6))\n",
    "msno.matrix(df)\n",
    "plt.title(f'Missing Value Matrix - {data_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_clean_df = fed_df_filter[['date', 'cpi', 'fed_rate', 'consumer_confidence','vix', 'oil', 'nonfarm_payrolls',\n",
    "       'treasury_yield', 'industrial_production', 'retail_sales', 'pmi',\n",
    "        'day_of_week', 'is_holiday', 'is_working_day']].dropna()\n",
    "fed_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the Date Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the first DataFrame\n",
    "merged_stock_data = AAPL_clean_df.copy()\n",
    "\n",
    "# List of stock DataFrames (excluding the first one)\n",
    "stock_dfs = [MSFT_clean_df, GOOGL_clean_df, NVDA_clean_df, AMZN_clean_df,\n",
    "             META_clean_df, TSLA_clean_df, AVGO_clean_df, AMD_clean_df, CRM_clean_df]\n",
    "\n",
    "# Merge each stock DataFrame on 'date' using a left join\n",
    "for df in stock_dfs:\n",
    "    merged_stock_data = pd.merge(merged_stock_data, df, on='date', how='inner')\n",
    "\n",
    "# 2. Merge with Macro and Fed DataFrames\n",
    "\n",
    "# Merge stock data with macro data\n",
    "merged_data = pd.merge(merged_stock_data, macro_clean_df, on='date', how='inner')\n",
    "\n",
    "# Merge with fed data\n",
    "final_merged_df = pd.merge(merged_data, fed_clean_df, on='date', how='inner')\n",
    "\n",
    "stock_df = merged_stock_data\n",
    "stock_macro_df = merged_data\n",
    "stock_macro_fed_df = final_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total of trade for the top 10 stock companies per day and their percentage\n",
    "stock_macro_fed_df[\"invest_total\"] = (stock_macro_fed_df[\"invest_AAPL\"] +\n",
    "                                stock_macro_fed_df[\"invest_MSFT\"] +\n",
    "                                stock_macro_fed_df[\"invest_GOOGL\"] +\n",
    "                                stock_macro_fed_df[\"invest_NVDA\"] +\n",
    "                                stock_macro_fed_df[\"invest_AMZN\"] +\n",
    "                                stock_macro_fed_df[\"invest_META\"] +\n",
    "                                stock_macro_fed_df[\"invest_TSLA\"] +\n",
    "                                stock_macro_fed_df[\"invest_AVGO\"] +\n",
    "                                 stock_macro_fed_df[\"invest_AMD\"] +\n",
    "                                stock_macro_fed_df[\"invest_CRM\"] )\n",
    "\n",
    "stock_macro_fed_df[\"invest_AAPL_ratio\"] = stock_macro_fed_df[\"invest_AAPL\"]/stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_MSFT_ratio\"] = stock_macro_fed_df[\"invest_MSFT\"] /stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_GOOGL_ratio\"] = stock_macro_fed_df[\"invest_GOOGL\"] /stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_NVDA_ratio\"] = stock_macro_fed_df[\"invest_NVDA\"] /stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_AMZN_ratio\"] = stock_macro_fed_df[\"invest_AMZN\"] /stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_META_ratio\"] = stock_macro_fed_df[\"invest_META\"] /stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_TSLA_ratio\"] = stock_macro_fed_df[\"invest_TSLA\"] /stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_AVGO_ratio\"] = stock_macro_fed_df[\"invest_AVGO\"] /stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_AMD_ratio\"] = stock_macro_fed_df[\"invest_AMD\"] /stock_macro_fed_df[\"invest_total\"]\n",
    "stock_macro_fed_df[\"invest_CRM_ratio\"] = stock_macro_fed_df[\"invest_CRM\"] /stock_macro_fed_df[\"invest_total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time extraction \n",
    "stock_macro_fed_df['day_of_week'] = stock_macro_fed_df['date'].dt.dayofweek       # 0 = Monday\n",
    "stock_macro_fed_df['month'] = stock_macro_fed_df['date'].dt.month                 # 1 = January\n",
    "stock_macro_fed_df['week_number'] = stock_macro_fed_df['date'].dt.isocalendar().week  # ISO week number\n",
    "stock_macro_fed_df['is_month_end'] = stock_macro_fed_df['date'].dt.is_month_end.astype(int)  # 1 if end of month, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Feature Engineering and Stationarization Script\n",
    "# --- Setup ---\n",
    "df = stock_macro_fed_df.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# --- Macroeconomic, Indices, ETFs to be differenced ---\n",
    "macro_and_indices_cols = [\n",
    "    'cpi', 'fed_rate', 'consumer_confidence', 'vix', 'oil',\n",
    "    'nonfarm_payrolls', 'treasury_yield', 'industrial_production',\n",
    "    'retail_sales', 'pmi',\n",
    "    'S&P500_Index', 'Dow_Jones_Index', 'NASDAQ_Composite',\n",
    "    'Russell2000_Index', 'VIX_Index', 'Dollar_Index_DXY', 'Gold_Futures',\n",
    "    'WTI_Oil_Futures', 'Copper_Futures', 'Brent_Crude_Futures',\n",
    "    'Tech_Sector_ETF', 'Energy_Sector_ETF', 'Financial_Sector_ETF',\n",
    "    'ConsumerDiscretionary_ETF', 'Lithium_ETF', 'Semiconductor_ETF', 'Electricity_Proxy'\n",
    "]\n",
    "\n",
    "# --- Apply first differencing to macroeconomic and index columns ---\n",
    "for col in macro_and_indices_cols:\n",
    "    if col in df.columns:\n",
    "        df[f'{col}_diff'] = df[col].diff()\n",
    "\n",
    "# --- Stock Tickers ---\n",
    "stocks = ['AAPL', 'MSFT', 'GOOGL', 'NVDA', 'AMZN', 'META', 'TSLA', 'AVGO', 'AMD', 'CRM']\n",
    "\n",
    "# --- Feature Engineering for Stock Prices ---\n",
    "for stock in stocks:\n",
    "    for field in ['close', 'open', 'high', 'low']:\n",
    "        col = f'{field}_{stock}'\n",
    "        if col in df.columns:\n",
    "            # Differencing to make stationary\n",
    "            df[f'{col}_diff'] = df[col].diff()\n",
    "            # Rolling means and std devs\n",
    "            df[f'{col}_rolling_mean_5'] = df[col].rolling(window=5).mean()\n",
    "            df[f'{col}_rolling_std_5'] = df[col].rolling(window=5).std()\n",
    "            df[f'{col}_rolling_mean_20'] = df[col].rolling(window=20).mean()\n",
    "            df[f'{col}_rolling_std_20'] = df[col].rolling(window=20).std()\n",
    "            # Lags\n",
    "            for lag in [1, 3, 5, 10]:\n",
    "                df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "\n",
    "    # --- Technical Indicators (on close prices) ---\n",
    "    close_col = f'close_{stock}'\n",
    "    if close_col in df.columns:\n",
    "        df[f'{stock}_RSI'] = ta.rsi(df[close_col], length=14)\n",
    "        macd = ta.macd(df[close_col])\n",
    "        if macd is not None:\n",
    "            df[f'{stock}_MACD'] = macd['MACD_12_26_9']\n",
    "            df[f'{stock}_MACD_signal'] = macd['MACDs_12_26_9']\n",
    "            df[f'{stock}_MACD_hist'] = macd['MACDh_12_26_9']\n",
    "\n",
    "    # --- Volume Features ---\n",
    "    vol_col = f'volume_{stock}'\n",
    "    if vol_col in df.columns:\n",
    "        df[f'{vol_col}_log'] = np.log1p(df[vol_col])\n",
    "        df[f'{vol_col}_diff'] = df[f'{vol_col}_log'].diff()\n",
    "\n",
    "    # --- Delta, Avg, Price Ratio, Invest Columns ---\n",
    "    for suffix in ['delta_price', 'avg_price', 'price_ratio', 'invest']:\n",
    "        derived_col = f'{suffix}_{stock}'\n",
    "        if derived_col in df.columns:\n",
    "            df[f'{derived_col}_diff'] = df[derived_col].diff()\n",
    "\n",
    "# --- Portfolio level investments ---\n",
    "portfolio_cols = ['invest_total', 'invest_AAPL_ratio', 'invest_MSFT_ratio', 'invest_GOOGL_ratio',\n",
    "                  'invest_NVDA_ratio', 'invest_AMZN_ratio', 'invest_META_ratio',\n",
    "                  'invest_TSLA_ratio', 'invest_AVGO_ratio', 'invest_AMD_ratio', 'invest_CRM_ratio']\n",
    "\n",
    "for col in portfolio_cols:\n",
    "    if col in df.columns:\n",
    "        df[f'{col}_diff'] = df[col].diff()\n",
    "\n",
    "# --- Drop rows with NaNs caused by rolling, diff, or lagging ---\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity Testing (ADF) for Time Series Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ˆ Stationarity Testing (ADF) for Time Series Modeling\n",
    "#from statsmodels.tsa.stattools import adfuller\n",
    "df\n",
    "# Prepare results list\n",
    "stationarity_results = []\n",
    "\n",
    "col_num = len(df.columns)\n",
    "# Loop over numeric columns and test stationarity\n",
    "for col in df.select_dtypes(include='number').columns:\n",
    "    try:\n",
    "        result = adfuller(df[col].dropna())\n",
    "        p_value = result[1]\n",
    "        is_stationary = p_value < (0.05 / col_num)\n",
    "        stationarity_results.append({\n",
    "            'Feature': col,\n",
    "            'ADF Statistic': result[0],\n",
    "            'p-value': p_value,\n",
    "            'Critical Value (5%)': result[4]['5%'],\n",
    "            'Stationary (p < 0.05)': is_stationary\n",
    "        })\n",
    "    except Exception as e:\n",
    "        stationarity_results.append({\n",
    "            'Feature': col,\n",
    "            'ADF Statistic': None,\n",
    "            'p-value': None,\n",
    "            'Critical Value (5%)': None,\n",
    "            'Stationary (p < 0.05)': False,\n",
    "            'Error': str(e)\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "stationarity_df = pd.DataFrame(stationarity_results)\n",
    "\n",
    "# Sort by p-value\n",
    "stationarity_df = stationarity_df.sort_values(by='p-value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Stationarity testing result\n",
    "stationarity_df['Stationary (p < 0.05)'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
