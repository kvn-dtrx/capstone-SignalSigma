{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddda985c",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20dccc3",
   "metadata": {},
   "source": [
    "# Unlocking Market Insight with LSTM\n",
    "\n",
    "## Introduction\n",
    "\"What if we could capture the hidden memory of the market?\"\n",
    "\n",
    "Markets are shaped by patterns, momentum, and historical context. While many models struggle to recognize these, LSTMs (Long Short-Term Memory networks) excel by remembering information over long periods. Let‚Äôs explore how LSTM technology unlocks deeper insights for stock market prediction.\n",
    "\n",
    "---\n",
    "\n",
    "## What is LSTM?\n",
    "LSTM stands for Long Short-Term Memory. It is a special kind of Recurrent Neural Network (RNN) capable of learning long-term dependencies.\n",
    "\n",
    "### Key Characteristics:\n",
    "- **Recursive Neural Network (RNN)** foundation, designed for sequence-based data.\n",
    "- **LSTM cells** use gates (input, forget, output) to control information flow.\n",
    "- Enables **selective memory retention** and **long-term dependency learning**.\n",
    "\n",
    "---\n",
    "\n",
    "## How Does LSTM Work?\n",
    "LSTM networks process data through a series of steps within each LSTM cell:\n",
    "- **Input Gate**: Determines which values from the input to update.\n",
    "- **Forget Gate**: Decides what information to discard.\n",
    "- **Output Gate**: Chooses the output based on the cell state.\n",
    "\n",
    "These mechanisms allow the network to maintain and update memory over time, solving issues like the vanishing gradient problem common in standard RNNs.\n",
    "\n",
    "---\n",
    "\n",
    "## Why LSTM for Stock Markets?\n",
    "Stock markets are inherently temporal and noisy. LSTM models outperform others due to their ability to:\n",
    "\n",
    "- **Capture long-term dependencies** across market cycles.\n",
    "- **Recognize complex patterns** in sequential data that span long time periods.\n",
    "- **Handle multivariate inputs**, such as price, volume, sentiment, and macroeconomic data.\n",
    "- **Adapt to temporal dynamics**, critical for understanding momentum and volatility.\n",
    "- **Avoid vanishing gradient issues** with their advanced memory cell architecture.\n",
    "\n",
    "---\n",
    "\n",
    "## Applications Beyond Finance\n",
    "LSTMs have demonstrated success in many fields, reinforcing their versatility:\n",
    "- **Text and speech modeling** (e.g., NLP, chatbots)\n",
    "- **Machine translation**\n",
    "- **Anomaly detection in time series**\n",
    "- **Text classification and sentiment analysis**\n",
    "\n",
    "Their ability to understand **temporally dynamic** and **sequential data** makes them valuable across domains.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "In a world where data flows in sequences and time-dependent patterns, LSTMs provide a powerful tool. For financial markets, this means:\n",
    "- Better prediction of future trends.\n",
    "- More adaptive, memory-driven strategies.\n",
    "- Competitive edge in a data-rich, fast-changing environment.\n",
    "\n",
    "LSTM: Because in the markets, memory is money.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc7e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed_combined_data.csv\")\n",
    "# features = df[['close_NVDA', 'oil',\"Electricity_Proxy\", \"Semiconductor_ETF\", \"Lithium_ETF\", \"Gold_Futures\",\"VIX_Index\",\"Gold_Futures\" ]].values\n",
    "features = df[['close_NVDA']].values  #seems to work best\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(features.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01601ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=60):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i - seq_length:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 20  # seems to be better when small\n",
    "X, y = create_sequences(scaled_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a49bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(len(X) * 0.8)\n",
    "# X_train, y_train = X[:train_size], y[:train_size]\n",
    "# X_test, y_test = X[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab25b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[0], 1)))\n",
    "# model.add(LSTM(units=50))\n",
    "# model.add(Dense(units=1))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# predicted = model.predict(X_test)\n",
    "# predicted_prices = scaler.inverse_transform(np.array(predicted).reshape(-1, 1))\n",
    "# actual_prices = scaler.inverse_transform(np.array(y_test).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# plt.plot(actual_prices, color=\"black\", label=\"Echter Preis\")\n",
    "# plt.plot(predicted_prices, color=\"green\", label=\"Vorhergesagter Preis\")\n",
    "# plt.title(\"LSTM Aktienkurs Vorhersage (X_test)\")\n",
    "# plt.xlabel(\"Zeit\")\n",
    "# plt.ylabel(\"Preis\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc9545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_predicted = model.predict(X_train)\n",
    "# train_predicted_prices = scaler.inverse_transform(train_predicted)\n",
    "\n",
    "# plt.plot(range(seq_length, seq_length + len(train_predicted_prices)),\n",
    "#          train_predicted_prices, label=\"Vorhergesagt (Train)\", color=\"blue\")\n",
    "\n",
    "# # Plot f√ºr echte Testpreise\n",
    "# plt.plot(range(seq_length + len(train_predicted_prices),\n",
    "#                seq_length + len(train_predicted_prices) + len(actual_prices)),\n",
    "#          actual_prices, label=\"Echter Preis (Test)\", color=\"black\")\n",
    "\n",
    "# # Plot f√ºr vorhergesagte Testpreise\n",
    "# plt.plot(range(seq_length + len(train_predicted_prices),\n",
    "#                seq_length + len(train_predicted_prices) + len(predicted_prices)),\n",
    "#          predicted_prices, label=\"Vorhergesagt (Test)\", color=\"green\")\n",
    "\n",
    "# # Trennlinie\n",
    "# plt.axvline(x=seq_length + len(train_predicted_prices), color='red', linestyle='--', label='Train/Test-Split')\n",
    "\n",
    "# plt.title(\"LSTM Aktienkurs Vorhersage\")\n",
    "# plt.xlabel(\"Zeit (Index)\")\n",
    "# plt.ylabel(\"Preis\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c1ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# mse = mean_squared_error(actual_prices, predicted_prices)\n",
    "# rmse = np.sqrt(mse)\n",
    "# mae = mean_absolute_error(actual_prices, predicted_prices)\n",
    "# r2 = r2_score(actual_prices, predicted_prices)\n",
    "\n",
    "# print(f\"üìä MSE  = {mse:.4f}\")\n",
    "# print(f\"üìä RMSE = {rmse:.4f}\")\n",
    "# print(f\"üìä MAE  = {mae:.4f}\")\n",
    "# print(f\"üìà R¬≤   = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90bfea",
   "metadata": {},
   "source": [
    "# mit Timeseries cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080426a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def create_model(input_shape=(20, 1)): #inputshape defalt was (60,1)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1)) \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "cv_mae_scores = []\n",
    "cv_r2_scores = []\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "    print(f\"Fold {fold+1}:\")\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    # Modell trainieren und bewerten\n",
    "    model = create_model()  \n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  R¬≤ : {r2:.4f}\")\n",
    "    cv_mae_scores.append(mae)\n",
    "    cv_r2_scores.append(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a332843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# # Fehler (Loss) f√ºr Training und Validierung plotten\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "# plt.title('Training & Validation Loss im Verlauf der Epochen')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage f√ºr Trainings- und Testdaten\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "# Vorhersage zur√ºckskalieren (um echte Preiswerte zu erhalten)\n",
    "train_pred = scaler.inverse_transform(train_pred)\n",
    "test_pred = scaler.inverse_transform(test_pred)\n",
    "y_train_actual = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_train_actual, label='Echte Preise (Train)', color='blue')\n",
    "plt.plot(train_pred, label='Vorhergesagt (Train)', color='green')\n",
    "plt.plot(range(len(y_train_actual), len(y_train_actual) + len(y_test_actual)), y_test_actual, label='Echte Preise (Test)', color='black')\n",
    "plt.plot(range(len(y_train_actual), len(y_train_actual) + len(test_pred)), test_pred, label='Vorhergesagt (Test)', color='red')\n",
    "\n",
    "plt.axvline(x=len(y_train_actual), color='red', linestyle='--', label='Train/Test-Split')\n",
    "\n",
    "plt.title('Vorhersage vs. Echte Werte')\n",
    "plt.xlabel('Zeit (Index)')\n",
    "plt.ylabel('Preis')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb3359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\\nDurchschnittlicher MAE √ºber alle Folds: {np.mean(cv_mae_scores):.4f}\")\n",
    "print(f\"Durchschnittlicher R¬≤  √ºber alle Folds: {np.mean(cv_r2_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd0a49",
   "metadata": {},
   "source": [
    "# -> Use  TimeSeriesSplit for cross validation!\n",
    "\n",
    "üîç **Vergleich der MAE:**\n",
    "\n",
    "- **Ohne CV:** `0.0554`  \n",
    "- **Mit CV:** / nur close `0.0147`\n",
    "- **Mit CV:** / nur close, inputshape(20,1), sequence 20  `0.0137`\n",
    "- **Mit CV:** / close, oil `0.0236`\n",
    "- **Mit CV** / 'close_NVDA', 'oil',\"Electricity_Proxy\", \"Semiconductor_ETF\", \"Lithium_ETF\", \"Gold_Futures\",\"VIX_Index\",\"Gold_Futures\" `0.0166`\n",
    "- **inputshape(20,1) anstatt (60,1)** `0.0151`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
